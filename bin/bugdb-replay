#!/usr/bin/env python

import csv
import logging
import os
import signal
import sys
import time
from enum import IntEnum
from multiprocessing import Process
from pathlib import Path
from queue import Queue
from random import shuffle
from threading import Thread
from typing import Any, Callable, Optional, Set, Tuple

import hase
from hase.symbex import tracer
from hase import progress_log

l = logging.getLogger(__name__)


def configure_logging() -> None:
    handler = logging.FileHandler("symbex-errors.log")
    handler.setLevel(logging.ERROR)
    tracer.l.addHandler(handler)
    handler = logging.FileHandler("progress.log")
    handler.setLevel(logging.INFO)
    progress_log.l.addHandler(handler)
    handler = logging.FileHandler("replay-errors.log")
    handler.setLevel(logging.ERROR)
    l.addHandler(handler)


class Result:
    def __init__(self, filename: str, result: str, error: Optional[str]) -> None:
        self.filename = filename
        self.result = result
        self.error = error


def log_result(result: Result) -> None:
    with open("results.csv", "a", newline="") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=["filename", "result", "error"])
        writer.writerow(result.__dict__)


def processed_traces() -> Set[str]:
    with open("results.csv", "r", newline="") as csvfile:
        reader = csv.DictReader(csvfile, fieldnames=["filename", "result", "error"])
        done = set()
        for r in reader:
            done.add(r["filename"])
    return done


def process_trace(trace: str) -> Optional[Result]:
    p = Path(trace)
    if p.name in processed_traces():
        return None

    try:
        hase.main(["hase", "replay", trace])
        r = Result(p.name, "succeed", None)
    except Exception as e:
        r = Result(p.name, "failed", repr(e))
        l.exception("hase replay {} failed".format(trace))
        if DEBUG:
            raise
    log_result(r)
    return r


class JobState(IntEnum):
    FINISHED = 1
    TIMEOUT = 2
    PENDING = 3
    FAILED = 4


def kill_process(process: Process) -> None:
    seconds = 120
    while process.is_alive() and seconds > 0:
        time.sleep(1)
        seconds -= 1
    assert process.pid is not None
    os.kill(process.pid, signal.SIGKILL)


class Job:
    def __init__(self, target: Callable, args: Tuple[Any]) -> None:
        self.process = Process(target=target, args=args)
        self.start_time = time.time()
        self.process.start()
        self.args = args

    def join(self, timeout: int) -> JobState:
        deadline = max(timeout - (time.time() - self.start_time), 0)
        self.process.join(0)
        if not self.process.is_alive():
            if self.process.exitcode == 0:
                return JobState.FAILED
            else:
                return JobState.FINISHED
        elif deadline == 0:
            self.process.terminate()
            Thread(target=kill_process, args=(self.process,)).start()
            return JobState.TIMEOUT
        else:
            return JobState.PENDING


DEBUG = False


def main() -> None:
    configure_logging()

    if not os.path.exists("results.csv"):
        open("results.csv", "w+", newline="").close()

    done = processed_traces()
    todo = []
    for arg in sys.argv[1:]:
        path = Path(arg).name
        if path not in done:
            todo.append(arg)

    shuffle(todo)
    if DEBUG:
        from ipdb import launch_ipdb_on_exception

        for path in todo:
            print(path)
            with launch_ipdb_on_exception():
                process_trace(path)
    else:
        jobs = Queue(maxsize=10) # type: Queue[Job]
        for path in todo:
            while jobs.full():
                hour = 60 * 60
                pending = []
                while not jobs.empty():
                    job = jobs.get()
                    res = job.join(24 * hour)
                    if res == JobState.PENDING:
                        pending.append(job)
                    elif res == JobState.TIMEOUT:
                        log_result(Result(Path(job.args[0]).name, "timeout", None))
                        l.exception("hase replay {} timeout".format(job.args[0]))
                for job in pending:
                    jobs.put(job)
                time.sleep(1)

            jobs.put(Job(target=process_trace, args=(path,)))


if __name__ == "__main__":
    main()
